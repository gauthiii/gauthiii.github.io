<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Bio & Projects</title>
  <style>
    :root{
      --bg: #0b0e14;
      --panel: #121826;
      --muted: #94a3b8;
      --text: #e5e7eb;
      --accent: #7c3aed;
      --accent-2: #22d3ee;
      --ring: 0 0 0 3px rgba(124,58,237,.25);
      --radius: 16px;
      --shadow: 0 10px 30px rgba(2,6,23,.55);
      --code: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", monospace;
      --sans: Inter, ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, "Helvetica Neue", Arial, "Apple Color Emoji","Segoe UI Emoji";
    }
    * { box-sizing: border-box; }
    html, body { height: 100%; }
    body{
      margin:0;
      font-family: var(--sans);
      color: var(--text);
      background:
        radial-gradient(1200px 500px at 100% -100px, rgba(124,58,237,.12), transparent 60%),
        radial-gradient(900px 500px at -10% 10%, rgba(34,211,238,.10), transparent 60%),
        var(--bg);
    }
    header{
      position:sticky; top:0; z-index:10;
      backdrop-filter: blur(10px);
      background: linear-gradient(to right, rgba(11,14,20,.85), rgba(11,14,20,.65));
      border-bottom: 1px solid rgba(148,163,184,.15);
    }
    .wrap{ max-width: 1000px; margin: 0 auto; padding: 18px 18px; }
    .brand{
      display:flex; align-items:center; gap:12px; font-weight:700; letter-spacing:.3px;
    }
    .logo{
      width:32px; height:32px; border-radius:8px;
      background: conic-gradient(from 210deg, var(--accent), var(--accent-2), var(--accent));
      box-shadow: 0 0 0 2px rgba(124,58,237,.35), 0 8px 20px rgba(124,58,237,.35) inset;
    }
    .controls{ display:flex; gap:10px; align-items:center; margin-top:10px; flex-wrap: wrap;}
    .btn, .chip, .search{
      border: 1px solid rgba(148,163,184,.22);
      background: rgba(18,24,38,.7);
      color: var(--text);
      border-radius: 12px;
      padding: 10px 12px;
    }
    .btn{ cursor:pointer; transition:.2s transform, .2s box-shadow; }
    .btn:hover{ box-shadow: var(--ring); transform: translateY(-1px); }
    .search{
      flex:1 1 280px; display:flex; align-items:center; gap:8px;
    }
    .search input{
      background: transparent; border:0; outline:0; color:var(--text); width:100%;
      font-size: 14px;
    }
    main{ padding: 24px 18px 60px; }
    .section{
      max-width: 1000px; margin: 0 auto 26px;
      background: linear-gradient(180deg, rgba(18,24,38,.80), rgba(12,15,24,.80));
      border: 1px solid rgba(148,163,184,.16);
      border-radius: var(--radius);
      box-shadow: var(--shadow);
      overflow: clip;
    }
    .section-header{
      display:flex; align-items: center; justify-content: space-between;
      padding: 18px 18px; gap:12px;
      border-bottom: 1px solid rgba(148,163,184,.12);
      background: linear-gradient(to right, rgba(124,58,237,.12), transparent 60%);
    }
    .section-title{
      display:flex; align-items:center; gap:10px; font-weight:700;
    }
    .badge{
      font: 12px/1 var(--code); color:#c4b5fd;
      background: rgba(124,58,237,.15); border:1px solid rgba(124,58,237,.35);
      padding: 6px 8px; border-radius: 999px;
    }
    .content{
      padding: 18px; font-size: 15.5px; line-height: 1.7; color: #e6edf6;
      white-space: pre-wrap; word-wrap: break-word;
    }
    .card{
      margin: 18px; border: 1px solid rgba(148,163,184,.14);
      background: rgba(10,14,24,.55);
      border-radius: 14px; overflow: hidden;
    }
    .card-head{
      display:flex; justify-content: space-between; align-items: center; gap:10px;
      padding: 14px 14px;
      background: linear-gradient(180deg, rgba(255,255,255,.03), transparent);
      border-bottom: 1px solid rgba(148,163,184,.10);
    }
    .card-title{
      display:flex; align-items:center; gap:10px; font-weight: 700;
    }
    .pill{
      font: 11px/1 var(--code); color:#93c5fd; border:1px solid rgba(59,130,246,.35);
      background: rgba(59,130,246,.12); padding:6px 8px; border-radius: 999px;
    }
    .card-body{ padding: 14px; }
    .clamp{
      position:relative; max-height: 220px; overflow: hidden;
      mask-image: linear-gradient(180deg, #000 70%, transparent);
    }
    .card-actions{
      display:flex; gap:8px; padding: 0 14px 14px; flex-wrap: wrap;
    }
    .small{ font-size: 12px; color: var(--muted); }
    .ghost{
      border-color: rgba(148,163,184,.18);
      background: rgba(18,24,38,.45);
    }
    .footer{
      text-align:center; color:var(--muted); font-size:12px; padding: 20px 0 60px;
    }
    kbd{
      font-family: var(--code);
      background: #0f172a; border:1px solid rgba(148,163,184,.3);
      padding: 2px 6px; border-radius: 6px; font-size: 12px;
    }
    @media (max-width: 680px){
      .section-header{ align-items: start; flex-direction: column; }
    }
  </style>
</head>
<body>
  <header>
    <div class="wrap">
      <div class="brand">
        <div class="logo" aria-hidden="true"></div>
        <div>
          <div style="font-size:15px">Portfolio — Bio & Projects</div>
          <div class="small">Paste your long content in the code block variables at the bottom of this file.</div>
        </div>
      </div>

      <div class="controls">
        <div class="search" role="search">
          <svg width="16" height="16" viewBox="0 0 24 24" fill="none" aria-hidden="true"><path d="M21 21l-4.35-4.35M10.5 18a7.5 7.5 0 1 1 0-15 7.5 7.5 0 0 1 0 15Z" stroke="currentColor" stroke-width="1.6" stroke-linecap="round"/></svg>
          <input id="search" placeholder="Filter projects (live search)… e.g. ‘recommendation’, ‘AWS’, ‘SQL’" />
        </div>
        <button class="btn" id="expandAll">Expand All</button>
        <button class="btn ghost" id="collapseAll">Collapse All</button>
        <button class="btn" id="copyAll">Copy All Text</button>
      </div>
    </div>
  </header>

  <main>
    <!-- BIO -->
    <section class="section" id="bioSection" aria-labelledby="bioHeading">
      <div class="section-header">
        <div class="section-title">
          <svg width="18" height="18" viewBox="0 0 24 24" fill="none" aria-hidden="true"><path d="M12 12a5 5 0 1 0 0-10 5 5 0 0 0 0 10Zm7 10a7 7 0 0 0-14 0" stroke="currentColor" stroke-width="1.6" stroke-linecap="round"/></svg>
          <span id="bioHeading">Bio</span>
          <span class="badge" id="bioWords">—</span>
        </div>
        <div class="small">Tip: Press <kbd>⌘/Ctrl</kbd> + <kbd>F</kbd> to find inside sections</div>
      </div>
      <div class="content">
        <div id="bioContent" class="clamp"></div>
      </div>
      <div class="card-actions">
        <button class="btn" data-toggle="#bioContent">Read More</button>
        <button class="btn ghost" data-copy="#bioContent">Copy Bio</button>
      </div>
    </section>

    <!-- PROJECTS -->
    <section class="section" id="projectsSection" aria-labelledby="projectsHeading">
      <div class="section-header">
        <div class="section-title">
          <svg width="18" height="18" viewBox="0 0 24 24" fill="none" aria-hidden="true"><path d="M4 7h16M4 12h16M4 17h10" stroke="currentColor" stroke-width="1.6" stroke-linecap="round"/></svg>
          <span id="projectsHeading">Projects</span>
          <span class="badge" id="projectCount">—</span>
        </div>
        <div class="small">Rendered below in order: Project 1 → 4</div>
      </div>
      <div id="projectsList" class="content" style="padding: 12px;"></div>
    </section>

    <div class="footer">
      Built with plain HTML, CSS, and vanilla JS. No external libraries.
    </div>
  </main>

  <script>
/** ▼▼▼ PASTE YOUR LONG CONTENT INSIDE THESE BACKTICK STRINGS ▼▼▼ **/
const bio = `
I’m a Business Data Analyst with over 8 years of experience in the IT industry, where I’ve specialized in translating complex business requirements into scalable, data-driven solutions.

Over the years, I’ve had the opportunity to work across both Agile (Scrum, SAFe) and Waterfall environments — adapting my approach depending on the project type and stakeholder expectations. In Agile, I’m deeply involved in user story creation, backlog grooming, sprint planning, and retrospectives, while in Waterfall projects, I focus on requirement sign-offs, structured documentation, and stakeholder governance through detailed BRDs, FRDs, and RTMs.

My strength lies in bridging the gap between business and technology — collaborating closely with developers, data engineers, and end-users to make sure the final deliverable not only meets the business goals but is also technically sound and compliant.

I have extensive experience in data quality management and data governance — developing, validating, and deploying data privacy, lineage, and risk-management frameworks that comply with organizational and regulatory standards. My work often involves defining and enforcing data quality KPIs across multiple domains, ensuring accuracy, consistency, and completeness throughout the data lifecycle.

From a technical perspective, I’m proficient in advanced SQL and T-SQL, stored procedures, and data profiling techniques to extract insights and resolve complex queries across diverse systems. I’ve worked on Master Data Management (MDM) and data-warehousing initiatives, integrating data from platforms such as Oracle, SQL Server, Teradata, and Amazon S3. I’ve also used tools like Informatica PowerCenter and IDQ to configure resources, manage metadata, and maintain data lineage visibility for compliance and audit purposes.

My experience extends into data modeling — creating ER diagrams, star and snowflake schemas, and dimensional models for analytical systems. I ensure that both technical and non-technical stakeholders can understand data architecture by documenting business and technical metadata, ensuring traceability and transparency in governance documentation.

In terms of reporting and analytics, I’m proficient in SAS Advanced, Power BI, and Business Intelligence tools, where I’ve designed dynamic dashboards and automated reports to support data-driven decision-making. These reports often visualize project KPIs, performance metrics, and sprint health indicators such as burndown and velocity charts, especially when using tools like JIRA and Azure DevOps for Agile project management.

I’ve also been actively involved in data-warehousing and ETL processes — overseeing data masking, cleansing, validation, and profiling across staging and data marts. I’ve helped teams optimize ETL workflows to ensure efficient data movement, integrity, and compliance.

Lastly, I bring strong quality assurance and testing skills. I’ve created and executed test plans, scripts, and test cases for both manual and automated testing. I’ve also led User Acceptance Testing (UAT) phases, validating business requirements and ensuring system performance, reliability, and fault tolerance across web-based and client/server applications.

To sum up, I bring a balance of technical depth, analytical precision, and business acumen. My focus is always on transforming raw data into actionable insights, ensuring data governance and compliance, and fostering cross-functional collaboration that drives measurable business outcomes.

`;

const project1 = `
At Capital One in McLean, Virginia, I’m working as a Business Data Analyst on a project titled KYC & AML Compliance Implementation.

The goal of this initiative is to enhance Know Your Customer (KYC) and Anti-Money Laundering (AML) processes to ensure strict adherence to regulatory standards such as BSA (Bank Secrecy Act), AMLA (Anti-Money Laundering Act), FATF (Financial Action Task Force), GDPR (General Data Protection Regulation), OFAC (Office of Foreign Assets Control), SEC (Securities and Exchange Commission), and FINRA (Financial Industry Regulatory Authority). The project involves integrating data from multiple systems, automating compliance alerts, improving data quality, and delivering dashboards that support risk management and audit readiness.

From an Agile-Scrum perspective, I operate within a cross-functional squad of compliance officers, data engineers, and developers. Each sprint is two weeks, and I participate actively in daily stand-ups, sprint planning, backlog grooming, sprint reviews, and retrospectives.

I partner closely with the Product Owner and Scrum Master to prioritize user stories and refine Product Backlog Items (PBIs), ensuring every story directly aligns with business value in risk mitigation or regulatory compliance. I maintain backlog hygiene, define acceptance criteria, and ensure all PBIs meet our Definition of Ready (DoR) before commitment.

At the start of the project, I helped define the vision, scope, and regulatory objectives, documenting timelines, ROI expectations, and compliance deliverables in a lightweight Agile charter. This gave our team and stakeholders a shared understanding of how each sprint increment supported the overall compliance roadmap.

I work closely with compliance and legal stakeholders to translate regulatory mandates into functional and technical requirements for KYC onboarding and AML monitoring systems. For example, I’ve mapped FATF and BSA obligations into system-level data rules and alert-generation logic to ensure that suspicious transactions trigger appropriate workflows.

On the process-modeling side, I’ve developed detailed AS-IS and TO-BE workflows for customer onboarding, transaction surveillance, and suspicious-activity reporting. Using Visio and Lucidchart, I modeled process bottlenecks and handoffs, which later guided our backlog items for automation and improvement.

I also perform data profiling, data validation, and source-to-target (STT) mapping across multiple systems — from customer information files to transaction databases — ensuring data accuracy, completeness, and consistency. Working closely with data governance teams, I’ve defined data-quality rules, access controls, and retention standards for sensitive customer and financial data.

A big part of my work involves analytics and visualization. I design SQL queries to identify anomalies and develop dashboards in Power BI and Tableau that visualize suspicious-activity trends, compliance KPIs, and regulatory metrics. These dashboards are used by senior management to make data-driven decisions on risk posture and audit readiness.

From a technical assurance standpoint, I collaborate with the ETL and data-engineering teams to monitor data pipelines, validate transformations, and ensure the integrity of data flowing into our compliance warehouse. I log and prioritize issues in JIRA, coordinate defect triage meetings, and verify fixes within the same sprint, following the Agile “inspect-and-adapt” philosophy.

On the testing side, I support UAT, regression, and QA testing — creating test cases, test data, and execution scenarios for KYC workflows and AML alerts. I participate in demo sessions to validate that each delivered increment satisfies both business and compliance acceptance criteria.

Every sprint concludes with retrospectives, where I help identify process improvements — whether that’s reducing backlog rollover, refining acceptance criteria, or automating validation scripts to save QA time.

Overall, this role has strengthened my ability to blend Agile delivery with regulatory precision. I’ve learned to ensure that each sprint not only delivers business value but also upholds data governance, risk mitigation, and audit transparency — enabling Capital One to maintain a proactive, compliant, and data-driven culture.

`;

const project2 = `
At Morgan Stanley in New York, I worked as a Business Data Analyst on an enterprise-level project to develop comprehensive documentation and process frameworks for a web-based loan origination and servicing system.

The system supported mortgage loan origination, servicing, processing, and commercial lending operations. It also covered syndicated loan workflows used by agent banks and lenders to reconcile daily positions, transactions, and contract information. The broader objective was to improve operational transparency, data integrity, and regulatory compliance while streamlining workflows for loan officers, underwriters, and servicing teams.

From an Agile standpoint, I was part of a cross-functional Scrum team. I participated in daily stand-ups, sprint planning, backlog grooming, sprint reviews, and retrospectives, ensuring smooth sprint cadence and communication across business and technical stakeholders.

Working with the Product Owner and Scrum Master, I helped prioritize user stories and refine acceptance criteria for features related to loan origination, servicing, escrow management, and commercial lending. My goal was to ensure that each story delivered compliance value and operational efficiency in line with CFPB, Fannie Mae, and Freddie Mac standards.

I collaborated extensively with mortgage loan officers, underwriters, processors, and servicing teams to capture detailed business rules and operational workflows. I documented loan approval criteria, underwriting workflows, exception handling, delinquency management, and escrow analyses, so that all processes were clearly traceable for audit and risk teams.

A key component of my role was conducting gap analysis between the existing legacy processes and the new enterprise platform. This analysis helped us identify redundant steps, improve data flow, and enhance compliance with federal and investor guidelines. Many of these optimizations were later integrated into the sprint backlog as process-improvement stories.

I also worked on documenting interfaces with third-party vendors — such as credit bureaus, appraisal vendors, title agencies, and payment processors — to ensure secure and compliant data exchange. I created data-flow diagrams and interface documentation to detail how information moved between systems, ensuring privacy and integrity of borrower and loan data.

For the syndicated loan operations, I analyzed and documented agent bank workflows for daily position reconciliation and loan lifecycle tracking, ensuring accuracy and alignment with inter-bank data exchange protocols. I also prepared system documentation that described each workflow step — from initiation to reconciliation — including exception handling, data validation, and reporting.

On the data side, I partnered with data-engineering teams to validate ETL processes migrating loan data from legacy platforms into the new system. I developed source-to-target (STT) mapping documents for key mortgage data elements such as loan contracts, underwriting details, collateral, escrow accounts, and payment histories.

I also performed data validation and reconciliation, ensuring that migrated loan records reflected accurate borrower details, loan balances, and escrow components. I created data validation rules and test cases to check for completeness, consistency, and regulatory compliance during migration.

Additionally, I documented migration procedures, fallback plans, and exception workflows to ensure business continuity during system cutovers. Once the migration was complete, I validated system outputs and data flows across modules to ensure all transactions aligned with compliance rules and operational accuracy.

On the testing side, I worked closely with QA and UAT teams, executing System Integration Testing (SIT) and User Acceptance Testing (UAT) across loan origination, servicing, and reporting modules. I provided business process knowledge, designed test scenarios, and verified that system behavior matched documented workflows and regulatory expectations.

Overall, my time at Morgan Stanley taught me how to combine Agile documentation practices, cross-functional collaboration, and deep domain expertise in mortgage and commercial lending. I helped create a unified framework that improved transparency, data quality, and compliance across all lending operations — contributing to smoother audits, more efficient loan servicing, and a faster time-to-close for customers.
`;

const project3 = `
At Discover Financial Services in Riverwoods, Illinois, I worked as a Business Data Analyst on the Enterprise Fraud Detection & Card Protection System.

The project’s objective was to build an enterprise-wide fraud detection platform capable of identifying suspicious credit card activity in real time, automatically blocking compromised accounts, and triggering secure card reissuance workflows. The ultimate goal was to reduce fraud losses, minimize customer disruption, and improve overall operational resilience.

From an Agile perspective, we followed a Scrum framework with bi-weekly sprints. I participated in all core ceremonies — daily stand-ups, backlog refinement, sprint planning, sprint reviews, and retrospectives — ensuring continuous alignment between fraud, risk, compliance, and technical teams. My role was to bridge regulatory requirements and system functionality so that every sprint increment delivered measurable compliance and fraud-mitigation value.

Working closely with Product Owners and Scrum Masters, I helped prioritize fraud-prevention features in the backlog, ensuring a balance between customer experience and compliance mandates such as PCI DSS, AML, and BSA. I authored user stories, epics, and acceptance criteria in JIRA, maintaining end-to-end traceability for all fraud-related features.

For example, one of my stories involved automating the “account-block-and-reissue” workflow. When a transaction triggered a high fraud score, the system automatically froze the account, generated a replacement card, and notified the customer via secure channels — all without human intervention.

I collaborated with fraud analysts and risk teams to define fraud-prevention processes such as customer notifications, escalation protocols, and fraud-alert triage, ensuring each process adhered to regulatory frameworks like KYC, AML, OFAC, and PCI DSS. I also drafted regulatory alignment documentation so that each system component could be audited for compliance.

On the technical side, I partnered with data-engineering teams to design and validate ETL pipelines that ingested real-time transaction feeds from both card networks and internal systems. I developed source-to-target mapping documents detailing key transaction attributes — merchant ID, MCC code, device ID, location, and cardholder profile — which served as the foundation for our fraud-scoring logic.

I also worked with third-party vendors to define API integration requirements for identity verification, biometric authentication, and document validation — ensuring smooth interoperability between Discover’s internal fraud systems and external partners.

My analytical work included writing complex SQL queries to investigate suspicious transaction clusters, validate fraud patterns, and monitor system performance. I performed data profiling, validation, and reconciliation to guarantee that every transaction feed was accurate, complete, and timely — since even minor latency could impact fraud detection effectiveness.

I supported the data-science team by analyzing historical fraud patterns and validating key risk indicators (KRIs) used in our predictive fraud models. By correlating transaction data with historical loss cases, we helped fine-tune thresholds to minimize false positives while maintaining high detection accuracy.

On the visualization side, I collaborated with BI teams to enhance fraud dashboards in Power BI and Tableau. These dashboards provided real-time visibility into fraud trends, detection accuracy, and operational KPIs. I also helped develop self-service dashboards that allowed fraud analysts to filter and investigate cases dynamically without relying on engineering support.

I performed data-lineage analysis to ensure that fraud-signal attributes — such as device fingerprints, merchant risk categories, and behavioral scores — were correctly integrated into downstream reporting and monitoring systems for compliance and audit purposes.

During the testing phase, I developed end-to-end UAT test cases covering scenarios such as transaction monitoring, fraud alerts, account blocking, and card reissuance. I prepared both fraud and non-fraud test datasets simulating real-world card activity to validate detection models and ensure that PCI DSS and AML standards were met during UAT and regression testing.

Overall, this project strengthened my ability to operate in a fast-paced Agile environment while integrating real-time data, predictive analytics, and regulatory compliance. I learned how to manage the entire lifecycle — from requirement gathering and data mapping to UAT and dashboard delivery — ensuring that every sprint brought us closer to a safer, smarter, and more customer-centric fraud detection ecosystem.
`;

const project4 = `
At First Republic Bank in San Francisco, I worked as a Business Systems Analyst on the Digital Payments Enhancement project, where the main focus was to modernize the bank’s digital payment infrastructure and improve operational efficiency across business payment processes.

The initiative involved developing a Business Payment Platform (BPP) that integrated wire transfers, payment approvals, and multi-account management into one unified digital experience. I also contributed to a digital payments program with Coupa, designed to accelerate supplier payments and streamline business-to-business payment cycles. Additionally, I supported the transition to the FIS IBS core banking platform, a major modernization effort that aimed to make payment processing more secure and efficient across digital channels.

My work began with requirement gathering and process modeling. I collaborated directly with business units, project managers, and senior stakeholders to define functional, non-functional, and technical requirements. I developed Business Process Flows, AS-IS and TO-BE diagrams, and performed detailed business analysis to understand existing challenges in the payments landscape and propose optimized future-state workflows.

Using tools like Microsoft Visio and UML, I created class diagrams, sequence diagrams, and state diagrams to capture system behavior and interaction flows between core modules such as wire processing, account management, and approval routing. This visual modeling made it easier for both business users and developers to align on functionality and technical expectations.

I also took part in business process reengineering (BPR) sessions, where I analyzed user feedback and documented change requests in real time. This helped reduce redundancy and improve automation in approval processes.

A critical aspect of my work involved authoring key documentation — including the Business Requirement Document (BRD), Functional Requirement Document (FRD), Software Requirement Specification (SRS), and Functional Specification Document (FSD). These documents ensured complete traceability of every business need to its implementation and test cases.

I conducted Joint Application Design (JAD) sessions with management, SMEs, and vendors to resolve open issues, review requirements, and refine feature definitions. I also maintained the Requirements Traceability Matrix (RTM) to ensure that every requirement was implemented and validated before release, securing stakeholder approval at each milestone.

On the data and testing side, I frequently used SQL queries to extract and validate data from the backend systems. This allowed me to verify transaction data integrity during testing and identify discrepancies in wire or payment workflows.

I managed business requirements and the product backlog in HP Quality Center, ensuring that all changes were tracked and properly tested in subsequent iterations. I worked closely with the testing and QA teams to develop test plans, test data, and test cases, and actively participated in resolving defects, performing impact analysis, and collecting test metrics for reporting.

I supported multiple testing phases — including Product Testing, Integration Testing, System Testing, and User Acceptance Testing (UAT) — ensuring that both business and technical objectives were met. During UAT, I collaborated with business users to verify that digital payment functionalities — like multi-account transfers, approval workflows, and supplier payouts — performed accurately and met compliance expectations.

Another unique contribution was helping design a standardized design system for digital payment interfaces, ensuring a consistent and user-friendly experience across platforms. This became part of the larger initiative to unify the look and feel of First Republic Bank’s digital products.

Overall, my experience at First Republic laid the foundation for my Agile systems analysis journey — I learned how to balance structured documentation with iterative development, how to collaborate across cross-functional teams, and how to apply both technical and business perspectives to deliver scalable, compliant, and user-focused digital banking solutions.
`;
/** ▲▲▲ END USER CONTENT ▲▲▲ **/

/* ---------- Utility ---------- */
const el = (sel, root=document) => root.querySelector(sel);
const els = (sel, root=document) => Array.from(root.querySelectorAll(sel));
const words = (txt) => (txt || "").trim().split(/\s+/).filter(Boolean).length;
const createCard = ({title, body, index})=>{
  const card = document.createElement("article");
  card.className = "card";
  card.dataset.index = index;

  card.innerHTML = `
    <div class="card-head">
      <div class="card-title">
        <svg width="16" height="16" viewBox="0 0 24 24" fill="none" aria-hidden="true"><path d="M6 19V5a2 2 0 0 1 2-2h7l3 3v13a2 2 0 0 1-2 2H8a2 2 0 0 1-2-2Z" stroke="currentColor" stroke-width="1.6"/></svg>
        <span>${title}</span>
        <span class="pill">${words(body)} words</span>
      </div>
    </div>
    <div class="card-body">
      <div class="clamp text" style="white-space: pre-wrap;">${escapeHtml(body)}</div>
    </div>
    <div class="card-actions">
      <button class="btn" data-toggle=".text">Read More</button>
      <button class="btn ghost" data-copy=".text">Copy</button>
    </div>
  `;
  return card;
};

const escapeHtml = (s="") =>
  s.replace(/[&<>"']/g, ch => ({'&':'&amp;','<':'&lt;','>':'&gt;','"':'&quot;',"'":'&#39;'}[ch]));

/* ---------- Render ---------- */
(function init(){
  // Bio
  const bioNode = el("#bioContent");
  bioNode.innerHTML = escapeHtml(bio);
  el("#bioWords").textContent = `${words(bio)} words`;

  // Projects
  const projects = [project1, project2, project3, project4];
  const projectsList = el("#projectsList");
  projects.forEach((p, i)=>{
    const title = `Project ${i+1}`;
    projectsList.appendChild(createCard({title, body: p, index: i}));
  });
  el("#projectCount").textContent = `${projects.filter(Boolean).length} items`;

  // Read More / Copy handlers
  document.addEventListener("click", (e)=>{
    const t = e.target;
    if(!(t instanceof HTMLElement)) return;

    // Toggle clamp
    if(t.matches("[data-toggle]")){
      const targetSel = t.getAttribute("data-toggle");
      const scope = t.closest(".section, .card") || document;
      const target = el(targetSel, scope);
      if(!target) return;
      const isClamped = target.classList.contains("clamp");
      target.classList.toggle("clamp");
      t.textContent = isClamped ? "Show Less" : "Read More";
    }

    // Copy
    if(t.matches("[data-copy]")){
      const targetSel = t.getAttribute("data-copy");
      const scope = t.closest(".section, .card") || document;
      const target = el(targetSel, scope);
      if(!target) return;
      const plain = target.textContent || "";
      navigator.clipboard.writeText(plain).then(()=>{
        const prev = t.textContent;
        t.textContent = "Copied ✓";
        setTimeout(()=> t.textContent = prev, 1100);
      });
    }
  });

  // Expand/Collapse All
  el("#expandAll").addEventListener("click", ()=>{
    els(".clamp").forEach(n => n.classList.remove("clamp"));
    els('[data-toggle]').forEach(b => b.textContent = "Show Less");
  });
  el("#collapseAll").addEventListener("click", ()=>{
    els(".text, #bioContent").forEach(n => { if(!n.classList.contains("clamp")) n.classList.add("clamp"); });
    els('[data-toggle]').forEach(b => b.textContent = "Read More");
  });

  // Live Search over projects
  el("#search").addEventListener("input", (e)=>{
    const q = e.target.value.trim().toLowerCase();
    els("#projectsList .card").forEach(card=>{
      const txt = card.querySelector(".text")?.textContent?.toLowerCase() || "";
      card.style.display = txt.includes(q) ? "" : "none";
    });
  });
})();

/* ---------- Keyboard niceties ---------- */
document.addEventListener("keydown", (e)=>{
  if((e.ctrlKey || e.metaKey) && e.key.toLowerCase()==="b"){ // toggle bio clamp
    e.preventDefault();
    const btn = el('#bioSection [data-toggle]');
    if(btn) btn.click();
  }
});
  </script>
</body>
</html>
